import sys
import io
import logging
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
from scipy.optimize import minimize
from SALib.sample import saltelli
from SALib.analyze import sobol
import pdfkit

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# -------------------------------
# Simulation functions
# -------------------------------
def simulate_logistic(N0: float, r: float, K: float, T: int) -> np.ndarray:
    Ns = [N0]
    for _ in range(T):
        Ns.append(Ns[-1] + r * Ns[-1] * (1 - Ns[-1] / K))
    return np.array(Ns)

def simulate_ricker(N0: float, r: float, K: float, T: int) -> np.ndarray:
    Ns = [N0]
    for _ in range(T):
        Ns.append(Ns[-1] * np.exp(r * (1 - Ns[-1] / K)))
    return np.array(Ns)

def simulate_leslie(N0_vec: list, fertility: list, survival: list, T: int) -> np.ndarray:
    n = len(N0_vec)
    N = np.array(N0_vec, dtype=float)
    history = [N.copy()]
    L = np.zeros((n, n))
    L[0, :] = fertility
    for i in range(1, n):
        L[i, i-1] = survival[i-1]
    for _ in range(T):
        N = L.dot(N)
        history.append(N.copy())
    return np.array(history)

def simulate_delay(N0: float, r: float, K: float, T: int, tau: int) -> np.ndarray:
    Ns = [N0] * (tau + 1)
    for t in range(tau, T + tau):
        N_next = Ns[t] * np.exp(r * (1 - Ns[t - tau] / K))
        Ns.append(N_next)
    return np.array(Ns[:T + 1])

def simulate_stochastic(base_sim, N0: float, r: float, K: float, T: int, sigma: float = 0.1, repeats: int = 100) -> np.ndarray:
    runs = []
    progress = st.progress(0)
    for i in range(repeats):
        traj = base_sim(N0, r, K, T)
        noise = np.random.normal(0, sigma, size=traj.shape)
        runs.append(np.clip(traj + noise, 0, None))
        progress.progress((i + 1) / repeats)
    return np.array(runs)

# -------------------------------
# Export & GPT4 analysis
# -------------------------------
def export_csv(data, filename, model_type: str, simulation_params: str):
    df = pd.DataFrame(data)
    csv = df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="–°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ CSV",
        data=csv,
        file_name=f"{filename}.csv",
        mime="text/csv"
    )
    # GPT-4 –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
    import g4f
    snippet = str(data[:10]) + "..." if len(data) > 10 else str(data)
    response = g4f.ChatCompletion.create(
        model=g4f.models.gpt_4,
        messages=[{"role": "user", "content": f"–í—ã - –Ω–∞—É—á–Ω—ã–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏–º—É–ª—è—Ü–∏–∏."
                    f"\n–¢–∏–ø –º–æ–¥–µ–ª–∏: {model_type}"
                    f"\n–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {simulation_params}"
                    f"\n–î–∞–Ω–Ω—ã–µ (–ø–µ—Ä–≤—ã–µ 10 —Ç–æ—á–µ–∫): {snippet}"}]
    )
    st.subheader("–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö GPT-4:")
    st.write(response)

# -------------------------------
# Analysis functions
# -------------------------------
def analyze_behavior(time_series: np.ndarray) -> str:
    std = np.std(time_series[-int(len(time_series)/2):])
    if std < 1e-3:
        return "–°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å"
    peaks = np.sum(np.diff(np.sign(np.diff(time_series))) < 0)
    if peaks > 5:
        return "–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∫–æ–ª–µ–±–∞–Ω–∏—è"
    return "–•–∞–æ—Å"


def sensitivity_heatmap(model_func, param_ranges: dict, fixed_args: dict, T: int):
    p1, p2 = list(param_ranges.keys())
    v1 = np.linspace(*param_ranges[p1])
    v2 = np.linspace(*param_ranges[p2])
    amp = np.zeros((len(v1), len(v2)))
    for i, x in enumerate(v1):
        for j, y in enumerate(v2):
            args = fixed_args.copy()
            args[p1], args[p2] = x, y
            ts = model_func(*args.values(), T)
            amp[i,j] = ts.max() - ts.min()
    fig, ax = plt.subplots()
    c = ax.pcolormesh(v1, v2, amp.T, shading='auto')
    fig.colorbar(c, ax=ax)
    ax.set_xlabel(p1)
    ax.set_ylabel(p2)
    return fig


def optimize_parameters(model_func, data: np.ndarray, initial_guess: list, bounds: list, T: int):
    def loss(params):
        sim = model_func(params[0], params[1], params[2], T)
        return np.mean((sim - data)**2)
    res = minimize(loss, initial_guess, bounds=bounds)
    return res


def generate_pdf_report(html_content: str, output_path: str = "report.pdf"):
    pdfkit.from_string(html_content, output_path)
    return output_path

# -------------------------------
# Streamlit UI
# -------------------------------
st.set_page_config(page_title="Population Dynamics Simulator", layout="wide")
st.title("üå± –°–∏–º—É–ª—è—Ç–æ—Ä –ü–æ–ø—É–ª—è—Ü–∏–æ–Ω–Ω–æ–π –î–∏–Ω–∞–º–∏–∫–∏ —Å –ê–Ω–∞–ª–∏–∑–æ–º")

# Sidebar: –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
models = {
    "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç": simulate_logistic,
    "–ú–æ–¥–µ–ª—å –†–∏–∫–µ—Ä–∞": simulate_ricker,
    "–ú–æ–¥–µ–ª—å –õ–µ—Å–ª–∏": lambda N0, r, K, T: simulate_leslie(N0, r, K, T),  # –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    "–ú–æ–¥–µ–ª—å —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π": lambda N0, r, K, T: simulate_delay(N0, r, K, T, tau),
    "–°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–º—É–ª—è—Ü–∏—è": lambda N0, r, K, T: simulate_stochastic(simulate_logistic, N0, r, K, T, sigma, repeats)
}
model_name = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", list(models.keys()))

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
T = st.sidebar.slider("–®–∞–≥–∏ –≤—Ä–µ–º–µ–Ω–∏ (T)", 10, 500, 100)
N0 = st.sidebar.number_input("–ù–∞—á–∞–ª—å–Ω–∞—è –ø–æ–ø—É–ª—è—Ü–∏—è N0", 0.0, 1000.0, 10.0)
r = st.sidebar.number_input("–¢–µ–º–ø —Ä–æ—Å—Ç–∞ r", 0.0, 5.0, 0.5)
K = st.sidebar.number_input("–ï–º–∫–æ—Å—Ç—å —Å—Ä–µ–¥—ã K", 1.0, 1000.0, 100.0)

# –î–æ–ø. –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
tau = st.sidebar.number_input("–ó–∞–¥–µ—Ä–∂–∫–∞ œÑ (–¥–ª—è –º–æ–¥–µ–ª–∏ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π)", 1, 10, 2)
sigma = st.sidebar.number_input("œÉ (–¥–ª—è —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–π)", 0.0, 1.0, 0.1)
repeats = st.sidebar.number_input("–ü–æ–≤—Ç–æ—Ä–µ–Ω–∏—è (–¥–ª—è —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–π)", 1, 200, 50)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –õ–µ—Å–ª–∏
n = st.sidebar.number_input("–ß–∏—Å–ª–æ –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤", 2, 10, 3)
fertility = [st.sidebar.number_input(f"f_{i}", 0.0, 1.0, 0.5) for i in range(n)]
survival = [st.sidebar.number_input(f"s_{i}", 0.0, 1.0, 0.8) for i in range(n-1)]
N0_vec = [st.sidebar.number_input(f"N0_{i}", 0.0, 100.0, 10.0) for i in range(n)]

# File uploader
uploaded = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å CSV –¥–ª—è –ø–æ–¥–≥–æ–Ω–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤", type=["csv"])

if st.sidebar.button("–°–∏–º—É–ª–∏—Ä–æ–≤–∞—Ç—å"):
    # –ó–∞–ø—É—Å–∫ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    if model_name in ["–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç", "–ú–æ–¥–µ–ª—å –†–∏–∫–µ—Ä–∞"]:
        ts = models[model_name](N0, r, K, T)
    elif model_name == "–ú–æ–¥–µ–ª—å –õ–µ—Å–ª–∏":
        ts = simulate_leslie(N0_vec, fertility, survival, T)
    elif model_name == "–ú–æ–¥–µ–ª—å —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π":
        ts = simulate_delay(N0, r, K, T, tau)
    else:
        ts = simulate_stochastic(simulate_logistic, N0, r, K, T, sigma=sigma, repeats=repeats)

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∞–Ω–∞–ª–∏–∑
    st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {model_name}")
    st.line_chart(pd.DataFrame(ts if ts.ndim==1 else ts))
    st.write(f"–†–µ–∂–∏–º –ø–æ–≤–µ–¥–µ–Ω–∏—è: {analyze_behavior(ts.flatten())}")

    # –°–∫–∞—á–∞—Ç—å CSV –∏ GPT-–∞–Ω–∞–ª–∏–∑
    export_csv(ts, model_name.replace(" ", "_"), model_name, f"N0={N0}, r={r}, K={K}, tau={tau}, sigma={sigma}")

    # –ê–Ω–∞–ª–∏–∑ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    if st.sidebar.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –∞–Ω–∞–ª–∏–∑ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"):
        fig = sensitivity_heatmap(
            models[model_name],
            {'r': (0.1,1.0,20), 'K': (50,200,20)},
            {'N0': N0, 'r': r, 'K': K},
            T
        )
        st.subheader("–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–∞–º–ø–ª–∏—Ç—É–¥–∞)")
        st.pyplot(fig)

    # –ü–æ–¥–≥–æ–Ω–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    if uploaded is not None:
        df = pd.read_csv(uploaded)
        data = df.iloc[:,1].values if df.shape[1]>1 else df.iloc[:,0].values
        res = optimize_parameters(models[model_name], data, [N0, r, K], [(0,None),(0,None),(0,None)], T)
        st.subheader("–ü–æ–¥–≥–æ–Ω–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        st.write(f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ: N0={res.x[0]:.2f}, r={res.x[1]:.2f}, K={res.x[2]:.2f}")

    # –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç
    if st.sidebar.button("–°–∫–∞—á–∞—Ç—å PDF –æ—Ç—á—ë—Ç"):
        html = st.experimental_get_query_params()
        path = generate_pdf_report(str(html))
        st.success(f"–û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {path}")

st.sidebar.markdown("---")
st.sidebar.info("–†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ –õ–∏–µ–π –ê—Ö–º–µ—Ç–æ–≤–æ–π")
