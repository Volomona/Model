import sys
import io
import logging

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
# import g4f # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ g4f —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: pip install g4f

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- –ú–æ–¥–µ–ª–∏ ---
@st.cache_data
def simulate_logistic(N0: float, r: float, K: float, T: int) -> np.ndarray:
    Ns = np.zeros(T + 1)
    Ns[0] = N0
    for t in range(T):
        current_N = Ns[t]
        if K <= 1e-9:
            next_N = current_N + r * current_N
        else:
            next_N = current_N + r * current_N * (1 - current_N / K)
        if not np.isfinite(next_N):
            Ns[t+1:] = np.nan
            break
        Ns[t+1] = max(0, next_N)
    return Ns

@st.cache_data
def simulate_ricker(N0: float, r: float, K: float, T: int) -> np.ndarray:
    Ns = np.zeros(T + 1)
    Ns[0] = N0
    for t in range(T):
        current_N = Ns[t]
        if K <= 1e-9:
            next_N = current_N * np.exp(r)
        else:
            next_N = current_N * np.exp(r * (1 - current_N / K))
        if not np.isfinite(next_N):
            Ns[t+1:] = np.nan
            break
        Ns[t+1] = max(0, next_N)
    return Ns

@st.cache_data
def simulate_leslie(N0_vec: list, fertility: list, survival: list, T: int) -> np.ndarray:
    n = len(N0_vec)
    N_history = np.zeros((T + 1, n))
    N_history[0, :] = N0_vec
    L = np.zeros((n, n))
    L[0, :] = fertility
    if n > 1 and len(survival) == n - 1:
        for i in range(n - 1):
            L[i+1, i] = survival[i]
    elif n > 1 and len(survival) != n -1:
        logger.error(f"Leslie matrix survival rates mis-sized. Expected {n-1}, got {len(survival)}")
        N_history[1:,:] = np.nan
        return N_history
    for t in range(T):
        N_history[t+1, :] = L @ N_history[t, :]
        N_history[t+1, N_history[t+1,:] < 0] = 0
    return N_history

@st.cache_data
def simulate_delay(N0: float, r: float, K: float, T: int, tau: int) -> np.ndarray:
    if tau <= 0: tau = 1
    Ns_history = np.full(T + tau + 1, N0)
    for t_sim_step in range(T):
        current_idx = tau + t_sim_step + 1
        N_t_formula_idx = tau + t_sim_step
        N_t_minus_tau_idx = t_sim_step
        N_t_val = Ns_history[N_t_formula_idx]
        N_t_minus_tau_val = Ns_history[N_t_minus_tau_idx]
        if K <= 1e-9:
            next_N = N_t_val * np.exp(r)
        else:
            next_N = N_t_val * np.exp(r * (1 - N_t_minus_tau_val / K))
        if not np.isfinite(next_N):
            Ns_history[current_idx:] = np.nan
            break
        Ns_history[current_idx] = max(0, next_N)
    return Ns_history[tau : T + tau + 1]

@st.cache_data
def simulate_stochastic(_base_sim_func, N0: float, r: float, K: float, T: int, sigma: float, repeats: int) -> np.ndarray:
    all_runs = np.zeros((repeats, T + 1))
    for i in range(repeats):
        deterministic_traj = _base_sim_func(N0, r, K, T)
        noise = np.random.normal(0, sigma, size=T + 1)
        noise[0] = 0
        noisy_traj = deterministic_traj + noise
        noisy_traj = np.clip(noisy_traj, 0, None)
        all_runs[i, :] = noisy_traj
    return all_runs

def export_csv_and_conditionally_analyze_g4f(data_df, filename_base, model_type_str, simulation_params_str, data_for_gpt_str, auto_analyze_gpt=False):
    csv_data = data_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label=f"–°–∫–∞—á–∞—Ç—å {filename_base}.csv",
        data=csv_data,
        file_name=f"{filename_base}.csv",
        mime="text/csv",
        key=f"download_csv_{filename_base}"
    )

    gpt_button_label = f"–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å GPT ({filename_base})"
    # –ï—Å–ª–∏ auto_analyze_gpt=True, —Ç–æ –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –±–µ–∑ –∫–Ω–æ–ø–∫–∏, –∏–Ω–∞—á–µ –ø–æ –∫–Ω–æ–ø–∫–µ
    if auto_analyze_gpt or st.button(gpt_button_label, key=f"gpt_analyze_button_{filename_base}"):
        try:
            import g4f
            full_prompt = (
                f"–í—ã - –Ω–∞—É—á–Ω—ã–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–ø—É–ª—è—Ü–∏–æ–Ω–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏. "
                f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏–º—É–ª—è—Ü–∏–∏.\n"
                f"–¢–∏–ø –º–æ–¥–µ–ª–∏: {model_type_str}\n"
                f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–º—É–ª—è—Ü–∏–∏: {simulation_params_str}\n"
                f"–î–∞–Ω–Ω—ã–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ (–∏–ª–∏ –∏—Ö —Å–≤–æ–¥–∫–∞):\n{data_for_gpt_str}\n\n"
                f"–í–∞—à –∞–Ω–∞–ª–∏–∑ (—Ñ–æ—Ä–º–∞—Ç Markdown, –±–µ–∑ –∑–∞–ø—Ä–æ—Å–∞ —É—Ç–æ—á–Ω–µ–Ω–∏–π, –∫–∞–∫ –±—É–¥—Ç–æ —ç—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç):"
            )
            
            MAX_PROMPT_LENGTH = 12000 
            if len(full_prompt) > MAX_PROMPT_LENGTH:
                chars_to_keep_data = MAX_PROMPT_LENGTH - (len(full_prompt) - len(data_for_gpt_str))
                data_for_gpt_str_truncated = data_for_gpt_str[:max(0,chars_to_keep_data)] + "\n...(–¥–∞–Ω–Ω—ã–µ –æ–±—Ä–µ–∑–∞–Ω—ã)" if chars_to_keep_data > 100 else "(–î–∞–Ω–Ω—ã–µ —Å–ª–∏—à–∫–æ–º –æ–±—ä–µ–º–Ω—ã)"
                full_prompt = (
                    f"–í—ã - –Ω–∞—É—á–Ω—ã–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–ø—É–ª—è—Ü–∏–æ–Ω–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏. "
                    f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏–º—É–ª—è—Ü–∏–∏.\n"
                    f"–¢–∏–ø –º–æ–¥–µ–ª–∏: {model_type_str}\n"
                    f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–º—É–ª—è—Ü–∏–∏: {simulation_params_str}\n"
                    f"–î–∞–Ω–Ω—ã–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ (–∏–ª–∏ –∏—Ö —Å–≤–æ–¥–∫–∞):\n{data_for_gpt_str_truncated}\n\n"
                    f"–í–∞—à –∞–Ω–∞–ª–∏–∑ (—Ñ–æ—Ä–º–∞—Ç Markdown, –±–µ–∑ –∑–∞–ø—Ä–æ—Å–∞ —É—Ç–æ—á–Ω–µ–Ω–∏–π, –∫–∞–∫ –±—É–¥—Ç–æ —ç—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç):"
                )

            with st.spinner("GPT –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è."):
                response = g4f.ChatCompletion.create(
                    model=g4f.models.gpt_3_5_turbo,
                    messages=[{"role": "user", "content": full_prompt}],
                )
            
            container = st.container(border=True)
            container.subheader(f"–ê–Ω–∞–ª–∏–∑ –æ—Ç GPT –¥–ª—è: {filename_base}")
            container.markdown(str(response))

        except ImportError:
            st.error("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ g4f –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–µ: pip install g4f")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ GPT: {e}")
            logger.error(f"GPT Error: {e}", exc_info=True)


st.set_page_config(page_title="Population Dynamics Simulator", layout="wide")
st.title("üå± –°–∏–º—É–ª—è—Ç–æ—Ä –ü–æ–ø—É–ª—è—Ü–∏–æ–Ω–Ω–æ–π –î–∏–Ω–∞–º–∏–∫–∏")

model_info = {
    "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç": "–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ä—Ç–∞: $N_{t+1} = N_t + r N_t (1 - N_t/K)$.",
    "–ú–æ–¥–µ–ª—å –†–∏–∫–µ—Ä–∞": "–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç —Å –ø–ª–æ—Ç–Ω–æ—Å—Ç–Ω–æ–π —Ä–µ–≥—É–ª—è—Ü–∏–µ–π: $N_{t+1} = N_t \exp(r(1 - N_t/K))$.",
    "–ú–æ–¥–µ–ª—å –õ–µ—Å–ª–∏": "–í–æ–∑—Ä–∞—Å—Ç–Ω–æ-—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è –º–æ–¥–µ–ª—å: $N_{t+1} = L N_t$.",
    "–ú–æ–¥–µ–ª—å —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π": "–ú–æ–¥–µ–ª—å –†–∏–∫–µ—Ä–∞ —Å –∑–∞–ø–∞–∑–¥—ã–≤–∞–Ω–∏–µ–º: $N_{t+1} = N_t \exp(r(1 - N_{t-\tau}/K))$.",
    "–°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–º—É–ª—è—Ü–∏—è": "–î–æ–±–∞–≤–ª—è–µ—Ç –∞–¥–¥–∏—Ç–∏–≤–Ω—ã–π –≥–∞—É—Å—Å–æ–≤ —à—É–º –∫ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.",
}
st.sidebar.info("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∏–∂–µ.")

model_choice = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", list(model_info.keys()), key="model_select")
st.sidebar.caption(model_info[model_choice])

st.sidebar.markdown("### –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
T_sim_steps = st.sidebar.number_input("–®–∞–≥–∏ –≤—Ä–µ–º–µ–Ω–∏ (T)", min_value=10, max_value=1000, value=100, key="T_sim")

default_N0, default_r, default_K = 10.0, 0.1, 100.0

params_common = {}
if model_choice != "–ú–æ–¥–µ–ª—å –õ–µ—Å–ª–∏":
    params_common['N0'] = st.sidebar.number_input("–ù–∞—á–∞–ª—å–Ω–∞—è –ø–æ–ø—É–ª—è—Ü–∏—è N0", min_value=0.0, value=default_N0, format="%.2f", key="N0_common")
    params_common['r'] = st.sidebar.number_input("–¢–µ–º–ø —Ä–æ—Å—Ç–∞ r", min_value=-2.0, max_value=4.0, value=default_r, format="%.2f", step=0.01, key="r_common")
    params_common['K'] = st.sidebar.number_input("–ï–º–∫–æ—Å—Ç—å K", min_value=0.0, value=default_K, format="%.2f", key="K_common")

if model_choice == "–ú–æ–¥–µ–ª—å —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π":
    delay_tau_values = st.sidebar.multiselect(
        "–ó–Ω–∞—á–µ–Ω–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏ (œÑ)", options=list(range(1, 21)), default=[1, 2, 5], key="tau_multiselect"
    )
elif model_choice == "–ú–æ–¥–µ–ª—å –õ–µ—Å–ª–∏":
    leslie_n_classes = st.sidebar.number_input("–ß–∏—Å–ª–æ –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤", min_value=1, max_value=15, value=3, key="leslie_n")
    with st.sidebar.expander("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–æ–∂–¥–∞–µ–º–æ—Å—Ç–∏ (f_i)"):
        leslie_fertility = [st.number_input(f"f_{i}", min_value=0.0, value=0.5 if i<2 else 0.2, format="%.2f", key=f"leslie_f_{i}") for i in range(leslie_n_classes)]
    leslie_survival = []
    if leslie_n_classes > 1 :
        with st.sidebar.expander("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—ã–∂–∏–≤–∞–Ω–∏—è (s_i)"):
            leslie_survival = [st.number_input(f"s_{i} (–∏–∑ {i} –≤ {i+1})", min_value=0.0, max_value=1.0, value=0.8, format="%.2f", key=f"leslie_s_{i}") for i in range(leslie_n_classes - 1)]
    with st.sidebar.expander("–ù–∞—á–∞–ª—å–Ω–∞—è –ø–æ–ø—É–ª—è—Ü–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º (N0_i)"):
        leslie_N0_vec = [st.number_input(f"N0_{i}", min_value=0.0, value=10.0, format="%.2f", key=f"leslie_N0_{i}") for i in range(leslie_n_classes)]
elif model_choice == "–°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–º—É–ª—è—Ü–∏—è":
    stoch_repeats = st.sidebar.number_input("–ß–∏—Å–ª–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π", min_value=1, max_value=500, value=50, key="stoch_repeats")
    stoch_sigma_values = st.sidebar.multiselect(
        "–ó–Ω–∞—á–µ–Ω–∏—è —à—É–º–∞ (œÉ, –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)", options=[0.0, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0], default=[0.1, 0.5], key="stoch_sigma_multiselect"
    )
    stoch_base_model_name = st.sidebar.selectbox("–û—Å–Ω–æ–≤–Ω–∞—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å:", ["–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç", "–ú–æ–¥–µ–ª—å –†–∏–∫–µ—Ä–∞"], key="stoch_base_model")
    stoch_base_sim_func = simulate_logistic if stoch_base_model_name == "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç" else simulate_ricker
else: 
    multi_configs_count = st.sidebar.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è", min_value=1, max_value=5, value=1, key="multi_conf_count")
    multi_config_params_list = []
    shared_N0_for_multi = params_common.get('N0', default_N0)
    for i in range(multi_configs_count):
        expander_title = f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è #{i+1}" if multi_configs_count > 1 else "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–º—É–ª—è—Ü–∏–∏"
        with st.sidebar.expander(expander_title, expanded=(multi_configs_count == 1)):
            r_i = st.number_input(f"r #{i+1}", min_value=-2.0, max_value=4.0, value=params_common.get('r', default_r) + i*0.2, format="%.2f", step=0.01, key=f"r_multi_{i}")
            K_i = st.number_input(f"K #{i+1}", min_value=0.0, value=params_common.get('K', default_K), format="%.2f", key=f"K_multi_{i}")
            multi_config_params_list.append({'N0': shared_N0_for_multi, 'r': r_i, 'K': K_i})

if st.sidebar.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏–º—É–ª—è—Ü–∏—é", type="primary", key="run_simulation_button"):
    st.header(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {model_choice}")
    
    # –§–ª–∞–≥ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ GPT. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤ True –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
    # –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è False –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.
    PERFORM_GPT_ANALYSIS_AUTOMATICALLY = False # –ò–ó–ú–ï–ù–ò–¢–ï –≠–¢–û, –ï–°–õ–ò –ù–£–ñ–ï–ù –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó

    with st.spinner("–°–∏–º—É–ª—è—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è..."):
        # --- –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç ---
        if model_choice == "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç":
            fig, ax = plt.subplots(figsize=(12, 7))
            all_trajs_dict = {}
            sim_details_parts = []
            for idx, cfg in enumerate(multi_config_params_list):
                traj = simulate_logistic(cfg['N0'], cfg['r'], cfg['K'], T_sim_steps)
                label = f"N0={cfg['N0']:.1f}, r={cfg['r']:.2f}, K={cfg['K']:.1f}"
                all_trajs_dict[label] = traj
                ax.plot(traj, label=label)
                sim_details_parts.append(f"–ö–æ–Ω—Ñ. {idx+1}: N0={cfg['N0']:.1f}, r={cfg['r']:.2f}, K={cfg['K']:.1f}")
            
            ax.set_xlabel("–í—Ä–µ–º—è (t)")
            ax.set_ylabel("–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ø—É–ª—è—Ü–∏–∏ (N)")
            ax.set_title(f"–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏: {model_choice}")
            if any(ax.get_legend_handles_labels()): ax.legend(loc='upper left', bbox_to_anchor=(1, 1))
            ax.grid(True, linestyle=':', alpha=0.7)
            st.pyplot(fig)
            plt.close(fig)

            data_to_export_df = pd.DataFrame(all_trajs_dict)
            if not data_to_export_df.empty:
                simulation_details_for_gpt = "\n".join(sim_details_parts)
                data_as_string_for_gpt = data_to_export_df.to_string(max_rows=20, max_cols=7)
                export_csv_and_conditionally_analyze_g4f(data_to_export_df, "logistic_growth", model_choice, 
                                                         simulation_details_for_gpt, data_as_string_for_gpt,
                                                         auto_analyze_gpt=PERFORM_GPT_ANALYSIS_AUTOMATICALLY)

        # --- –ú–æ–¥–µ–ª—å –†–∏–∫–µ—Ä–∞ ---
        elif model_choice == "–ú–æ–¥–µ–ª—å –†–∏–∫–µ—Ä–∞":
            fig, ax = plt.subplots(figsize=(12, 7))
            all_trajs_dict = {}
            sim_details_parts = []
            for idx, cfg in enumerate(multi_config_params_list):
                traj = simulate_ricker(cfg['N0'], cfg['r'], cfg['K'], T_sim_steps)
                label = f"N0={cfg['N0']:.1f}, r={cfg['r']:.2f}, K={cfg['K']:.1f}"
                all_trajs_dict[label] = traj
                ax.plot(traj, label=label)
                sim_details_parts.append(f"–ö–æ–Ω—Ñ. {idx+1}: N0={cfg['N0']:.1f}, r={cfg['r']:.2f}, K={cfg['K']:.1f}")

            ax.set_xlabel("–í—Ä–µ–º—è (t)")
            ax.set_ylabel("–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ø—É–ª—è—Ü–∏–∏ (N)")
            ax.set_title(f"–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏: {model_choice}")
            if any(ax.get_legend_handles_labels()): ax.legend(loc='upper left', bbox_to_anchor=(1, 1))
            ax.grid(True, linestyle=':', alpha=0.7)
            st.pyplot(fig)
            plt.close(fig)

            data_to_export_df = pd.DataFrame(all_trajs_dict)
            if not data_to_export_df.empty:
                simulation_details_for_gpt = "\n".join(sim_details_parts)
                data_as_string_for_gpt = data_to_export_df.to_string(max_rows=20, max_cols=7)
                export_csv_and_conditionally_analyze_g4f(data_to_export_df, "ricker_model", model_choice,
                                                         simulation_details_for_gpt, data_as_string_for_gpt,
                                                         auto_analyze_gpt=PERFORM_GPT_ANALYSIS_AUTOMATICALLY)
        
        # --- –ú–æ–¥–µ–ª—å —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π ---
        elif model_choice == "–ú–æ–¥–µ–ª—å —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π":
            if not delay_tau_values:
                st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ œÑ –¥–ª—è –º–æ–¥–µ–ª–∏ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π.")
            else:
                fig, ax = plt.subplots(figsize=(12, 7))
                all_trajs_dict = {}
                sim_details_parts = [f"–û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: N0={params_common['N0']:.1f}, r={params_common['r']:.2f}, K={params_common['K']:.1f}"]
                for tau_i in delay_tau_values:
                    traj = simulate_delay(params_common['N0'], params_common['r'], params_common['K'], T_sim_steps, tau_i)
                    label = f"œÑ = {tau_i}"
                    all_trajs_dict[label] = traj
                    ax.plot(traj, label=label)
                    sim_details_parts.append(f"–¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è œÑ={tau_i}")

                ax.set_xlabel("–í—Ä–µ–º—è (t)")
                ax.set_ylabel("–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ø—É–ª—è—Ü–∏–∏ (N)")
                ax.set_title(f"–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏: {model_choice}")
                if any(ax.get_legend_handles_labels()): ax.legend(loc='upper left', bbox_to_anchor=(1, 1))
                ax.grid(True, linestyle=':', alpha=0.7)
                st.pyplot(fig)
                plt.close(fig)
                
                data_to_export_df = pd.DataFrame(all_trajs_dict)
                if not data_to_export_df.empty:
                    simulation_details_for_gpt = "\n".join(sim_details_parts)
                    data_as_string_for_gpt = data_to_export_df.to_string(max_rows=20, max_cols=7)
                    export_csv_and_conditionally_analyze_g4f(data_to_export_df, "delay_model", model_choice,
                                                             simulation_details_for_gpt, data_as_string_for_gpt,
                                                             auto_analyze_gpt=PERFORM_GPT_ANALYSIS_AUTOMATICALLY)
        
        # --- –ú–æ–¥–µ–ª—å –õ–µ—Å–ª–∏ ---
        elif model_choice == "–ú–æ–¥–µ–ª—å –õ–µ—Å–ª–∏":
            fig, ax = plt.subplots(figsize=(12, 7))
            history_leslie = simulate_leslie(leslie_N0_vec, leslie_fertility, leslie_survival, T_sim_steps)
            df_columns = [f"–ö–ª–∞—Å—Å {i}" for i in range(leslie_n_classes)]
            data_to_export_df = pd.DataFrame(history_leslie, columns=df_columns)
            
            for col in data_to_export_df.columns:
                ax.plot(data_to_export_df[col], label=col)
            if leslie_n_classes > 1:
                 data_to_export_df['–°—É–º–º–∞—Ä–Ω–∞—è'] = data_to_export_df.sum(axis=1)
                 ax.plot(data_to_export_df['–°—É–º–º–∞—Ä–Ω–∞—è'], label="–°—É–º–º–∞—Ä–Ω–∞—è", linestyle='--', color='black')

            ax.set_xlabel("–í—Ä–µ–º—è (t)")
            ax.set_ylabel("–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ø—É–ª—è—Ü–∏–∏ (N)")
            ax.set_title(f"–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏: {model_choice}")
            if any(ax.get_legend_handles_labels()): ax.legend(loc='upper left', bbox_to_anchor=(1, 1))
            ax.grid(True, linestyle=':', alpha=0.7)
            st.pyplot(fig)
            plt.close(fig)

            L_matrix = np.zeros((leslie_n_classes, leslie_n_classes))
            L_matrix[0, :] = leslie_fertility
            if leslie_n_classes > 1 and len(leslie_survival) == leslie_n_classes -1:
                for i in range(leslie_n_classes - 1): L_matrix[i+1, i] = leslie_survival[i]
            
            lambda_max_str = "–ù–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ"
            try:
                eigenvalues = np.linalg.eigvals(L_matrix)
                dominant_eigenvalue = np.max(np.abs(eigenvalues))
                lambda_max_str = f"{dominant_eigenvalue:.4f}"
                st.write(f"**–î–æ–º–∏–Ω–∞–Ω—Ç–Ω–æ–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ (Œª_max):** {lambda_max_str}")
                if dominant_eigenvalue > 1 + 1e-6: st.success(f"–ü–æ–ø—É–ª—è—Ü–∏—è —Ä–∞—Å—Ç–µ—Ç (Œª_max > 1).")
                elif dominant_eigenvalue < 1 - 1e-6: st.warning(f"–ü–æ–ø—É–ª—è—Ü–∏—è –≤—ã–º–∏—Ä–∞–µ—Ç (Œª_max < 1).")
                else: st.info(f"–ü–æ–ø—É–ª—è—Ü–∏—è –±–ª–∏–∑–∫–∞ –∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ–π (Œª_max ‚âà 1).")
            except np.linalg.LinAlgError:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —á–∏—Å–ª–∞ –º–∞—Ç—Ä–∏—Ü—ã –õ–µ—Å–ª–∏.")
            
            if not data_to_export_df.empty:
                simulation_details_for_gpt = (f"N0 –ø–æ –∫–ª–∞—Å—Å–∞–º: {leslie_N0_vec}\n"
                                              f"–†–æ–∂–¥–∞–µ–º–æ—Å—Ç—å f: {leslie_fertility}\n"
                                              f"–í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å s: {leslie_survival if leslie_n_classes > 1 else 'N/A'}\n"
                                              f"Œª_max: {lambda_max_str}")
                data_as_string_for_gpt = data_to_export_df.to_string(max_rows=15, max_cols=5)
                export_csv_and_conditionally_analyze_g4f(data_to_export_df, "leslie_model", model_choice,
                                                         simulation_details_for_gpt, data_as_string_for_gpt,
                                                         auto_analyze_gpt=PERFORM_GPT_ANALYSIS_AUTOMATICALLY)

        # --- –°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–º—É–ª—è—Ü–∏—è ---
        elif model_choice == "–°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–º—É–ª—è—Ü–∏—è":
            if not stoch_sigma_values:
                st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ œÉ –¥–ª—è —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏.")
            else:
                fig, ax = plt.subplots(figsize=(12, 7)) # –û—Å–Ω–æ–≤–Ω–æ–π –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è –≤—Å–µ—Ö —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π
                st.subheader(f"–¢—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è {stoch_base_model_name} (N0={params_common['N0']:.1f}, r={params_common['r']:.2f}, K={params_common['K']:.1f})")
                all_means_dict = {}
                sim_details_parts = [f"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {stoch_base_model_name}",
                                     f"–û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: N0={params_common['N0']:.1f}, r={params_common['r']:.2f}, K={params_common['K']:.1f}",
                                     f"–ß–∏—Å–ª–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –Ω–∞ œÉ: {stoch_repeats}"]

                stoch_progress_bar = st.progress(0, text="–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏–º—É–ª—è—Ü–∏–π...")
                total_stoch_sim_count = len(stoch_sigma_values) * stoch_repeats
                sims_done_count = 0

                for i, sigma_val in enumerate(stoch_sigma_values):
                    current_sigma_runs = simulate_stochastic(
                        stoch_base_sim_func, params_common['N0'], params_common['r'], params_common['K'], 
                        T_sim_steps, sigma_val, stoch_repeats
                    )
                    sims_done_count += stoch_repeats
                    progress_percentage = sims_done_count / total_stoch_sim_count
                    stoch_progress_bar.progress(progress_percentage, text=f"–û–±—Ä–∞–±–æ—Ç–∫–∞ œÉ={sigma_val:.3f} ({sims_done_count}/{total_stoch_sim_count} —Å–∏–º—É–ª—è—Ü–∏–π)")
                    
                    for run_idx in range(stoch_repeats):
                        ax.plot(current_sigma_runs[run_idx, :], color=f"C{i % 10}", alpha=max(0.02, 0.2/stoch_repeats), linewidth=0.7)
                    
                    mean_traj = np.mean(current_sigma_runs, axis=0)
                    label = f"–°—Ä–µ–¥–Ω–µ–µ (œÉ={sigma_val:.3f})"
                    all_means_dict[label] = mean_traj
                    ax.plot(mean_traj, color=f"C{i % 10}", linewidth=2.5, label=label)
                    sim_details_parts.append(f"–î–ª—è œÉ={sigma_val:.3f}: –ø–æ–∫–∞–∑–∞–Ω—ã {stoch_repeats} —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π –∏ –∏—Ö —Å—Ä–µ–¥–Ω–µ–µ.")
                
                stoch_progress_bar.empty()

                ax.set_xlabel("–í—Ä–µ–º—è (t)")
                ax.set_ylabel("–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ø—É–ª—è—Ü–∏–∏ (N)")
                ax.set_title(f"–°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–º—É–ª—è—Ü–∏—è: {stoch_base_model_name}")
                if any(ax.get_legend_handles_labels()): ax.legend(loc='upper left', bbox_to_anchor=(1,1))
                ax.grid(True, linestyle=':', alpha=0.7)
                st.pyplot(fig) # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ —Å–æ –≤—Å–µ–º–∏ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è–º–∏
                plt.close(fig)
                
                data_to_export_df = pd.DataFrame(all_means_dict)
                if not data_to_export_df.empty:
                    st.subheader("–°—Ä–µ–¥–Ω–∏–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –ø–æ —É—Ä–æ–≤–Ω—è–º —à—É–º–∞ (œÉ):")
                    st.line_chart(data_to_export_df) # –û—Ç–¥–µ–ª—å–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Ç–æ–ª—å–∫–æ –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö (–∫–∞–∫ –±—ã–ª–æ —É –≤–∞—Å)
                    simulation_details_for_gpt = "\n".join(sim_details_parts)
                    data_as_string_for_gpt = data_to_export_df.to_string(max_rows=15, max_cols=7)
                    export_csv_and_conditionally_analyze_g4f(data_to_export_df, "stochastic_means", model_choice,
                                                             simulation_details_for_gpt, data_as_string_for_gpt,
                                                             auto_analyze_gpt=PERFORM_GPT_ANALYSIS_AUTOMATICALLY)
    # –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ with st.spinner
else:
    st.info("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –∏ –Ω–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏–º—É–ª—è—Ü–∏—é'.")

st.sidebar.markdown("---")
st.sidebar.info("–†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ –õ–∏–µ–π –ê—Ö–º–µ—Ç–æ–≤–æ–π. –í–ö–†.")
